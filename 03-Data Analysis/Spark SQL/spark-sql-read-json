from pyspark.sql import SQLContext
sqlContext = SQLContext(sc)

df = sqlContext.read.json("/user/cloudera/people.json")

# Displays the content of the DataFrame to stdout
df.show()

# The inferred schema can be visualized using the printSchema() method.
df.printSchema()
# root
#  |-- age: integer (nullable = true)
#  |-- name: string (nullable = true)

# Register this DataFrame as a table.
df.registerTempTable("people")

# SQL statements can be run by using the sql methods provided by `sqlContext`.
teenagers = sqlContext.sql("SELECT name FROM people WHERE age >= 13 AND age <= 19")
